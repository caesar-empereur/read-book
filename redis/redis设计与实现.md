## 9章 服务器中的数据库

- 切换数据库
    * 客户端 select 命令切换数据库
    * 客户端 redisClient 的 db 属性记录当前指向的数据库，切换就是修改 db 的指向
    
- 数据库键空间
    * 1  redis 服务器中的每个数据库都有一个 redisDb 结构体的 [dict字典]() 保存所有的 **[key-value]()** ,称为键空间, 结构如下

        |键         | 键的数据结构       |
        |:-----------:|:-------------------:|
        |"list"     | 列表               |
        |"hash"     | 哈希表             |
        |"string"   | 字符串             |
    * 2 对 key value 的操作都是修改 dict 字典
    * 3 设置 key 的过期时间
        * redisDb 结构体的 **[expire过期字典]()** 保存了 key 对应的过期时间，结构如下
        
            |键             | 过期时间          |
            |:---------------:|:-------------------:|
            |"name" 键的指针 | 10秒             |
            |"age"  键的指针 | 20秒             |
            |"phone"键的指针 | 30秒             |
            
        * 修改删除过期时间都是对 expire 字典修改
        * 判断 key 是否过期
            * 每次获取 key 判断是否在 过期字典中，没有就直接返回
            * 有的话拿出过期时间与当前时间对比，过期则返回空，是否删除要根据策略

- 过期删除策略

    |删除策略     | 具体操作       | 优缺点   |
    |:------------:|:--------------------|:-------------------|
    |定时删除     | 设置键的过期时间时，创建一个定时器，时间一到就删除                |  内存友好，消耗 CPU  |
    |**惰性删除** | 每次获取key的时候再去检查是否过期，是就删除返回空，没就返回 value  | 占用内存，不消耗 CPU |
    |**定期删除** | 服务器每隔一点时间检查，删除过期键                                |  折中方案           |

- 过期删除对 RDB, AOF 文件的影响
    
     |顺序    | 操作       |
     |-----------|:-------------------|
     |1    | SAVE 命令生成 RDB 文件时，过期的键被检查到，不会写到 RDB 文件中   |
     |2     | redis 以 主 模式载入 RDB 时，过期的键不会载入 |
     |3   | redis 以 从 模式载入 RDB 时，过期键也会载入，等到主删除过期键时，会发送同步命令删除从的 |
     |4   | redis 以 AOF 模式运行时，过期键还没删除的也会写入 AOF, 只有过期时才向 AOF 文件追加 删除命令 |
     |5   | 主 发现并删除过期键时，会同步删除命令到从 |

## 10章 RDB持久化
   * 创建 RDB 文件
      * SAVE 命令，服务器会一直阻塞，期间无法接收命令
      * BGSAVE 命令，新建一个进程，不会阻塞
   * 载入 RDB 文件
      * 开启了 AOF 时，会载入 AOF 文件
      * 没开启 AOF 时，会载入 RDB 文件
      * 载入RDB期间，服务器会阻塞
   * **[RDB文件包含了全部的键值对数据]()**


## 11章 AOF持久化

   * AOF文件保存的是一条条的 **[写命令]()**，服务器每执行一条写命令，都会追加写入到 AOF 文件里
   
   * AOF 文件的载入还原
      * 服务器启动时，**读取AOF文件中的所有命令拿到数据库执行**
      * 命令是通过创建一个不带网络连接的 **[伪客户端]()** 执行的
      
   * **[AOF重写]()**
   
      |顺序    | 操作       |
     |-----------|:-------------------|
     |1     | 对于一个列表类型的键，只需要一条写命令记录全部数据, **多次写操作记录多条写命令**，AOF文件体积会很大|
     |2   | 后台获取键对应的数据后生成一条命令，写入2个缓冲区，后续键的数据有变化时 |
     |3   | 每一条写命令，后台会写入到 AOF **[缓冲区]()** 与 **[AOF重写缓冲区]()** |
     |4   | 两个缓冲区的数据都会写入到对应的文件，重写结束时，重写缓冲区文件替换掉 缓冲区文件 |

## 15章 复制

>> Redis的 **[复制]()** 功能分为 **[同步sync]()** 和 **[命令传播]()** 两个操作

>> **127.0.0.1:6378 > SLAVEOF 127.0.0.1:6379** ==> 6378 复制 6379

* **[同步]()** 操作用于将从的数据库状态更新至主当前所处的数据库状态
    
    |顺序    | 操作       |
     |-----------|:-------------------|
     |1    | 从向主发送SYNC命令   |
     |2     | 收到SYNC命令的主执行BGSAVE命令，在后台生成一个RDB文件 |
     |3   | 将BGSAVE命令生成的RDB文件发送给从 |
     |4   | 从将自己的数据库状态更新至主执行BGSAVE命令时的数据库状态。 |


- **[命令传播]()**

>> 目的 ：同步操作后致主从的数据库状态出现不一致时，让主从的数据库重新回到一致状态。

    * 1 主数据变化后，会将自己执行的写命令发送给从服务器执行
    * 2 当从执行了相同的写命令之后，主从将再次回到一致状态
    * 在命令传播阶段，从会以每秒一次的频率，向主发送命令

- **[旧版同步操作缺陷]()**

    |旧版同步操作 | 缺点       |
     |-----------|:-------------------|
     |主从同步过一次后断线再进行同步，会执行上一步的同步的内容 | 没有必要，需要的是需要同步断线后主变动的数据   |
     |同步操作耗时耗资源，需要主 执行 BGSAVE生成RDB文件传输给从 | 消耗CPU内存磁盘资源 |
     |从 接受到RDB文件后载入RDB文件| 这时服务器会阻塞，无法处理客户端请求 |


> Redis从2.8版本开始，使用 **[PSYNC]()** 命令代替SYNC命令来执行复制时的同步操作

- **[PSYNC]()** 命令具有 **[完整重同步]()** 和 **[部分重同步]()** 两种模式

    |PSYNC     | 初次复制       | 断线后重复制   |
    |:------------:|:--------------------|:-------------------|
    |完整重同步     | SYNC命令的执行一样，都是通过让主创建并发送RDB文件  |  '  |
    |部分重同步 | '  | 主从断开后, 主将断开期间主执行的写命令发送给从，从只要接收并执行这些写命令 |
    
    * **[部分重同步的原理]()**
        

        |顺序    | 操作       |
        |-----------|:-------------------|
        |1    | 主和从会分别维护一个复制偏移量   |
        |2     | 主每次向从传播N个字节的数据，就将自己的偏移量的值加上N |
        |3   | 从每次收到主传播来的N个字节的数据时，就将自己的偏移量的值加上N |
- PSYNC 命令的实现
    * PSYNC 从服务器 命令的调用方法有两种
        * 如果从以前没有复制过任何主, 从在开始一次新的复制时将向主发送PSYNC -1
        * 如果从已经复制过某个主，那么从在开始新的复制时将向主发送PSYNC ＜runid＞ ＜offset＞
    * PSYNC 主服务器返回3种回复
        * 如果主返回+FULLRESYNC runid offset，那么表示主将与从执行完整重同步操作
        * 如果主返回+CONTINUE回复，那么表示主将与从执行部分重同步操作
        * 如果主返回-ERR回复，那么表示主的版本低于Redis 2.8
        
## 16章 sentinel 哨兵模式
- 哨兵模式

    * 哨兵是 redis 的高可用解决方案
    * 一个或多个 哨兵实例组成哨兵系统，监控多个主从
    * 发现主服务器下线时，将某个从升级为主
    * sentinel 向多个从发送 复制 指令，故障转移完毕
    * 之前掉线的主恢复上线时，设置为从
    
- 哨兵模式的工作流程

    * 1 启动初始化 sentinel
        
        |顺序    | 操作       |
        |:-----------|:-------------------|
        1    | 初始化服务器，sentinel 是一个运行在 **[特殊环境]()** 下的 redis 服务   |
        2     | 将 redis 服务变成 sentinel 服务，sentinel 模式下，无法执行 set get 命令 |
        3   | 初始化 sentinel 状态下的 master 属性，记录了主服务器地址 |
        4   | 连接到 主，成为主的客户端，用来发送命令 |
    * 2 获取 主服 信息
        * 2.1 定时通过发送 INFO 命令到主来获取主服务器的信息
        * 2.2 主返回的信息包括主自己的信息，还有主下面的从服务器的地址状态等信息
    * 3 sentinel 发送 ping 命令到各个 redis 服务器，规定时间内没有返回回复的判断为 **[主观下线]()**
    * 4 sentinel 询问其他 sentinel 主观下线的 redis 服务是否也是下线，是的话就是 **[客观下线]()**
    * 5 选举领头 sentinel
        * 5.1 每个发现客观下线的 sentinel 都会发命令要求其他 sentinel 将自己设置为 领头 sentinel
        * 5.2 **[发命令是先到先得]()**，谁先发，谁先成为 领头
    * 6 **[故障转移]()** (领头sentinel选举后，需要对下线的主执行故障转移)
        
        |顺序    | 操作       |
        |-----------|:-------------------|
        |1    | 在主下的从里面，选一个变成主 |
        |2     | 让旧的从复制新的主数据 (修改之前的复制目标) |
        |3   | 下线的主设置为从，上线时再去复制新的主 |
        
## 17章 集群
> redis 集群可以提供相对于单机更可靠的服务

- 1 集群模式的建立
    * 1.1redis 服务启动时检查配置项 cluster-enable 是否开启
    * 1.2开启的话读取集群的地址信息，发送命令到指定服务器 CLUSTER MEET 建立连接创建集群
    * 1.3这时集群还不是上线状态
    
- 2 **[redis 为什么不用简单哈希处理 key？]()** 
    - 简单哈希就是对节点数量取模算出哪个节点来处理 key
    - 5个节点，set 命令保存数据分配到第一个，节点数量变化了，get 命令取模计算的时候算出来第二个，找不到数据了
    - 总结就是简单哈希在节点数量变化时会出现前后2次算出的节点不一样，导致set, get 操作拿不到 value
    
- 3 **[一致性哈希]()**
![一致性哈希](https://github.com/caesar-empereur/read-book/blob/master/photo/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C.png)

- 4 **[redis没有采用一致性哈希，而是用哈希槽的方式]()**

    - redis 为什么不采用一致性哈希？
        - 一致性哈希是一个环，节点数量少的时候，可能会出现数据倾斜的问题
        - 适用哈希槽的一个好处就是无论节点数量多少，都可以实现槽的均匀分布
        - 一致性哈希适合无状态的负载均衡，redis服务是有状态的，节点出现故障
    * 1 redis 集群通过 **[分片, 槽指派]()** 来保存数据，整个集群分配了 16384 个槽用来存储数据，**[每个节点处理一部分槽]()**
    * 2 **所有槽都有服务器接受处理时 集群才是上线状态**，只要有一个槽没人接收处理，就是 下线
    * 3 可以向集群下的节点发送命令，**指定节点处理的哪些槽** CLUSTER ADDSLOTS 0 1 2 ...5000
    * 4 每个节点记录自己的槽信息，**还会向其他的节点传播自己的槽信息**，节点两两互相传播
    * 5 **[重新分片]()**
        * **[当集群节点数量变化时，将某个节点下的一些槽重新分配到另一个节点，槽对应的key数据也会随着迁移]()**
        * 重新分片不需要集群下线，移动哈希槽的成本是非常低的
        * 重新分片操作是由Redis的集群软件redis-trib负责执行的

- 3 **[在集群中执行命令，key 的处理过程]()**
    - 虽然是集群模式，但是执行命令时仍然需要指定哪个节点处理
    * 1 某个节点接收到数据处理命令时，先算出 key 所属的槽是不是自己负责的，是的就处理数据
    * 2 不是自己负责的，找到槽对应的节点，返回客户端 **[MOVED]()** 错误 和 **[重定向]()** 指令
    * 3 **集群模式下客户端不会打印这个 MOVED 错误**，而是直接重定向到指定服务器 操作数据
    * 4 单机模式下，判断到key所属的槽不是自己的，客户端直接打印错误
   
   |'     | redis-trib 操作       | '   |
    |------------|:--------------------:|-------------------|
    |源节点     | ---->导入哪些槽      | **[1](#1)** 目标节点  |
    |源节点 **[2](#2)** | 导出哪些槽----->  | 目标节点 |
    |源节点 **[3](#3)** | 迁移槽对应的键数据------>   |  目标节点           |
    |源节点 | **[4](#4)** 通知整个集群 : 哪些槽被迁移到哪里   |  目标节点           |
    
- 5 **[复制]()** 与 **[故障转移]()**
    
    * 5.1 Redis集群中的节点分为主节点和从节点
    * 5.2 其中 **[主节点用于处理槽]()**，**[而从节点则用于复制某个主节点]()**
    * 5.3 主节点下线时，代替主节点继续处理命令请求
    
      | 模式的区别| 优缺点 |措施 |
      |-----------|-------------------|-------------------|
      |Sentinal | 高可用 |在master宕机时会自动将slave提升为master，继续提供服务 |
      |Cluster| 扩展性 |单个redis内存不足时，使用Cluster进行分片存储 |
 
## 19章 事务

- 1 事务的实现
    * 1.1 **[MULTI]()** 开始事务
    * 1.2 命令入队，**EXEC、DISCARD、WATCH、MULTI** 这4个命令会被马上执行，其他的命令会 返回 **QUEUED** 回复
    * 1.3 执行事务，EXEC 命令将队列的命令执行
    
```
WATCH命令是一个乐观锁，可以在EXEC命令执行之前，监视数据库键，并在EXEC命令执行时，
检查被监视的键是否已经被修改过，如果是的话，服务器将拒绝执行事务，
并向客户端返回代表事务执行失败的空回复
```

- 2 watch 命令的实现

    * 2.1 watch 命令的执行

        | 客户端A         | 客户端B         |
        |---------------- |-----------------|
        |watch "name"     |                 |
        |multi            |                 |
        |set "name" "hehe"|                 |
        |'                |set "name" "haha"|
        |返回 error       |                 |

    * 2.2 watch 命令的实现
        * 2.2.1 每个redis 服务器都会保存一个 watched 字典,结构如下

            | 键        | 监控的客户端<链表> |
            |-----------|-------------------|
            |"name"     | 客户端A -> 客户端B |
            |"age"      | 客户端C            |
            |"phone"    | 客户端D -> 客户端E | 

        * 2.2.2 watch 字典的检查过程
            * 1 所有对键数据修改的命令，都会检查服务器上的 watched 字典
            * 2 如果修改的键在字典中有，就会修改对应客户端的 一个 DIRTY_CAS 标记为 TRUE
            * 3 客户端发送到服务器的执行命令，服务器发现 DIRTY_CAS 为 TRUE, 说明安全性被破坏，返回错误
            
## redis 回收策略

- **[如何保证redis中10w数据都是热点数据？]()**
    - 数据库中有1000w的数据，而redis中只有50w数据，如何保证redis中10w数据都是热点数据？
    - 限定 Redis 占用的内存，Redis 会根据自身数据淘汰策略，留下热数据到内存
    - 计算一下 50W 数据大约占用的内存，然后设置一下 Redis 内存限制即可
    - 并将淘汰策略为volatile-lru或者allkeys-lru

| 回收策略   | 回收源 | 具体措施 |
|---------------- |-----------------|-----------------|
|volatile-lru | 设置过期时间的数据集 | 挑选最近最少使用的数据淘汰 |
|volatile-ttl |设置过期时间的数据集 | 挑选将要过期的数据淘汰 |
|volatile-random| 设置过期时间的数据集 | 任意选择数据淘汰 |
|allkeys-lru |数据集| 挑选最近最少使用的数据淘汰 |
|allkeys-random| 数据集 | 任意选择数据淘汰 |
|no-enviction|                 | 禁止驱逐数据 |


>> LRU（Latest Recent Used)

## redis 缓存时间与一致性问题

-
| 问题        | 描述 |解决方案|
|-----------|-------------------|-------------------|
|缓存穿透 | 一直查询缓存与数据库都没有的数据,每次都查2个地方，导致后端压力过大 |参数校验，key id<0直接返回，布隆过滤，用算法判断key在缓存种是否存在，不用直接查 |
|缓存雪崩 |大面积的key过期导致缓存挂掉导致所有请求转到数据库，造成数据库压力过大 |每个key过期时间不一样,分散开 |
|缓存击穿 | 热点key在某个时间内失效，有大量并发请求过来了，造成DB压力 | 布隆过滤，key获取value值为空时锁上，从数据库中load数据后再释放锁，其他线程等待锁释放 |

## redis 其他问题
    
   - redis 异步队列的实现
      * 用一个 list 结构的 key，rpush 消息，lpop 消息，没有获取到消息，sleep 一下
   - redis 与 mysql 数据一致性
      * 读是先读缓存，写是先写数据库再更新
      * 强一致性要求的场景不能使用 redis 缓存
   - **[布隆过滤器]()**
      - 布隆过滤器一种比较巧妙的概率型数据结构
      - 当它判断存在时不一定 (**[误判]()**)，不存在则是确定的
      - 实现原理是 **[位图]()** 与 **[哈希函数]()**
         - 先不断的存储字符串到位图中，哈希函数算出key的多个位
         - 然后判断这些位是不是已经被设置为1，其实就是与位图的位进行与操作
         - 多个哈希函数算出来的多个位只要与操作之后多个位全部改变，就证明这个key不存在
         - key 不存在添加成功，相当于 map 的 putIfNotExisted()
      - redis 有插件支持，key add 进去，判断是否存在是 用 exist
      - 用一个位数组和n个哈希函数，算出key 的哈希取模，得到n个数组索引值，把这些值置为1
      - 判断存在时也是用哈希取模的方式算出n个索引值，每个都为1则元素存在，有一个为0则不存在
      - 由于是哈希计算，**[时间复杂度为 O(1)]()**
      - 100亿个key, 每个key 64字节，布隆过滤器大小为25GB，远小于使用哈希表的640GB
      - 布隆过滤器可用于过滤网站黑名单，垃圾邮件，商品是否重复购买
   - **[redis 热点数据失效怎么处理]()**
      - 热点数据失效了，那就不要让它失效，不要设置失效时间
   - **[redis 怎么发现热点数据？]()**
      - 电商的热点商品的访问需要做成redis数据，怎么判断哪些商品的缓存key是热点的？
      - 1 认为预测
      - 2 系统推算统计(根据日志，访问统计)
      - 3 redis 内存淘汰机制设置为 allkeys-lfu, 再执行 ./redis-cli --hotkeys 就会返回访问量大的key
   - **[热门商品的热点key大部分集中在redis集群的某个结点上，造成数据倾斜，怎么处理？]()**
      - **[本地缓存，也就是缓存前置]()**
         - 这个方案需要对web应用做改造，redis访问到数据之后保存在应用本地的内存里
## redis 分布式锁
>> 使用同一个key，设置成功的话返回1，说明拿到锁，没有则等待，释放锁的时候把key删掉
- 操作方式
    * setnx(key1, value1);
    * del(key1)
- 延伸出来的问题

    - 1 del 的时候程序挂掉，没有del 成功，锁没有释放怎么办？
        * 答：给锁设置过期时间，防止没有释放锁
    - 2 客户端A的锁过期了，客户端B可以加锁，这时候有2个客户端持有锁，相当于锁失效了，怎么办？
        * 1 加大锁的超时时间，但不一定解决问题，因为业务逻辑执行时间是不确定的
        * 2 锁的value设置为一个UUID, 释放的时候判断是自己设置的UUID的锁再del
        
    - 2 因为key 都是一样的，一个客户端把另一个客户端的锁释放了，释放了不属于自己的锁，怎么办？
        * 答：锁的value设置为一个UUID, 释放的时候判断是自己设置的UUID的锁再del
        
    - 3 按照先判断锁的value再del，2步操作，不是原子性的，del 的时候自己的锁过期了，把别人的锁 del了，怎么办？
        * 答：判断自己的锁再del，整个操作用lua脚本来执行, redis 的 eval() 命令在执行lua脚本时，
                脚本会当作一个命令执行，执行完了再执行其他的
    - 4 集群环境中存放锁的服务器故障导致 **[2个客户端拥有锁的问题]()**
        ```
        集群环境中，存放锁的key的服务器挂掉，key没有转移到其他服务器上，导致原有的锁丢失，客户端发现可以加锁，
        于是产生了2个客户端同时拥有锁的过程
        ```
        - 答：采用 **[RedLock]()** 的解决方案
        
            - 1 在5个节点的redis集群中，使用key 和随机值的value 轮流在每台机器上获取锁
            - 2 只有在3个节点上获取到了锁，才算成功拿到锁
            - 3 拿到锁之后，计算花费的时间，把超时时间延长对应的花费时间
            - 4 规定时间(超时时间)内没拿到锁，到对应的redis节点上把key删掉(锁释放)
            - 5 锁释放的时候同样需要到对应的节点上把key删掉
        - RedLock 的具体实现
        
            - RedLock redLock = redissionClient.getLock() 尝试获取锁
            - redLock.tryLock(获取锁的规定时间, 失效时间, 时间单位);3
            - redLock.unlock()
    - 5 redis 分布式可重入锁
        * 获取锁失败的时候判断value是不是跟当前线程id一样，是的可以重入锁

## redis 单线程
- 为什么单线程的redis还这么快?
    - redis 的单线程是指 接收，读取，解析，返回都由主线程完成
    - 纯内存操作，没有磁盘访问，CPU 不是瓶颈
    - 其二就是异步IO，redis 中主要的IO 操作是 接收和返回
    - redis 中的IO 模型是非阻塞的，是 epoll 模型
    - 单线程避免了单线程的上下文切换，锁的竞争，内核态到用户态的切换
    - redis 处理的大部分时间消耗在 io 的读写上
    - 如果单线程还满足不了，可以集群模式，多进程单线程，处理能力提高
    
- redis 6.0 引入了多线程机制的原因
    - 配置文件里面加入  io-threads 4 开启4个io线程
    - 多线程加入之后的流程：
        - 主线程负责连接建立和读写事件
        - 主线程发现连接可读后，将连接加入等待队列，等待队列将连接分配 io 线程处理
        - io 线程读取数据，处理完成
        - 主线程等待所有 io 线程处理完之后，清空等待队列
        - redis 引入多线程后不会有并发问题，因为处理命令的还是单线程

## redis **[pipeline]()** 机制
```
普通的redis操作是一次请求，一次处理返回
当连续多次操作redis时，顺序执行需要等待每一步执行完才能下一次操作

pipeline 机制可以实现一次将多个redis操作变成一次请求，不需要等待，最后一次性处理即可

pipeline 机制可以提高吞吐量，但无法保证原子性，事务
```

## redis 与 mysql 双写数据一致性的问题
```
在高并发的业务场景下，数据库的性能瓶颈往往都是用户并发访问过大。所以，
一般都使用redis做一个缓冲操作，让请求先访问到redis，没有数据再访问 mysql,
更新的时候先更新mysql 再更新缓存。而不是直接去访问MySQL等数据库。从而减少网络请求的延迟响应
```
- **[数据为什么会不一致？]()**
    - 场景 1 （单库情况）- **[删除redis到更新mysql中间有插入数据到redis]()**
        - A请求写数据，先删除 redis，然后更新数据库的时候卡住(业务逻辑)
        - 这时候B请求访问redis没数据而访问数据库，并且跟新脏数据到 redis
    - 场景 2 （数据库读写分离）- **[主从复制延迟导致的]()**
        - A请求写数据，先删除 redis，然后更新到 mysql，没毛病
        - B请求读redis 没数据，然后读数据读的从库，复制延迟，然后把脏数据更新到 redis
    - 解决办法
        - **[延时双删]()**
            - 场景1的不一致是因为在删除缓存和写数据库之间有数据又写入到缓存了
            - 因此在 删除缓存，更新数据库之后再延时500ms后再次删除缓存，就能把中间插入到缓存的数据干掉
        - **[异步更新缓存(基于订阅binlog的同步机制)]()**
            - 读数据请求到 redis，写数据请求到 mysql
            - 数据写到 mysql 后，通过 binlog 日志订阅更新到 redis
            - 实际方案有阿里的 canal 工具，订阅 binlog 日志然后更新到 redis，类似主从复制
