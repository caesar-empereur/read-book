- count(*) 的各种性能区别
    -count(id)
        - innodb 会遍历整张表，取出每一行的id，返回给server, server统计数量
    - count(1)
        - innodb 会遍历整张表, 但不取值, server 在返回的每一行放一个 1 进去再统计数量
    - count(1) 执行得要比 count(id) 快
        - 因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作
    - count(字段)
        - 如果字段定义是 not null 的，根据行纪录统计数量
        - 如果字段定义是 null 的，根据行记录，找到字段判断，实际非空的才会统计数量

- 简单的查询语句出现速度很慢的可能
    - 可能出现锁表了
        - show processlist 命令输出 Waiting for table metadata lock 就是锁表
        - 这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了
        
        - 加读锁的时候，已经有写锁的话会读锁会阻塞
        - lock in share mode 如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住
    - 子查询结果行数过多，mysql 使用的临时表占用大量的空间
- 连接风暴
    - 连接风暴就是数据库连接数太多，无法创建更多连接，相当于应用不可用
    - 解决办法
        - 处理掉那些占着连接但是不工作的线程
            - mysql 的连接数统计是只要占用连接就算，不管当前语句状态是休眠还是运行
            - show processlist 命令找出 sleep 状态的线程
            - 这种休眠状态的连接可能是事务开始后在执行业务代码，还没提交
            - 直接kill掉对应的id的线程会导致事务没提交的话会回滚
            - 查询 information_schema 库的 innodb_trx 表 找到trx_mysql_thread_id等于刚刚show processlist的id
            - 关闭一个sql连接的命令是 kill connection id
- 数据库服务器占用内存很高的可能
    - 查看buffer pool 的设置，这个是存储引擎的缓冲池

- mysql 如何保证数据不丢失
    - 只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复
    - binlog 的写入机制
        - 事务的 binlog 是不能拆分的，不管事务多大，都要保证一次性写入
        - 事务执行过程中，先把日志写到 binlog cache
        - 事务提交的时候，再把 binlog cache 写到 binlog 文件中
        - binlog 是每个线程独有的
        - 在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能
        - 对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志
    - redo log 的写入机制
        - 事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 
        - redo log buffer 通过一定的机制持久化到磁盘，有3种策略
            - 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中
            - 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘
            - 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache
            - InnoDB 有一个后台线程，每隔1秒，就会把buffer中的日志，写到文件系统的page cache，然后调用fsync持久化到磁盘
    - binlog, redo log 是基于WAL机制的数据持久化前写日志的设计
        - 每次提交事务都要写2个日志，其实磁盘IO并不少，但是效率很高
        - redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快
        - 组提交机制，可以大幅度降低磁盘的 IOPS 消耗
    - 为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？
        - binlog 是不能被打断的。一个事务的binlog必须连续写，因此要整个事务完成后，再一起写到文件里
        - 一个线程只能有一个事务在执行
        - redo log 中间有生成的日志可以写到 redo log buffer 中,内容还能搭便车
    - 事务还没提交数据库挂掉了，会不会导致数据不一致
        - 不会，没提交的事务就不会持久化，因此不存在不一致的问题
    - mysql binlog 的日志格式和内容
        - 如果格式是 statement,就是保存原始的sql 语句

- 主备延迟产生的原因
    - 备库机器性能比主库差，导致binlog在备库重放的速度慢
    - 备库查询压力较大，主备架构的备经常备用来做查询，导致查询压力落到备库，影响了备库执行binlog速度
    - 大事务，也就是一次性修改的数据比较多，例如大表的DDL
    - mysql 主备高可用是依赖与主备延迟的，延迟时间越小，主备切换的时间越短
    - 例如备库延迟30分钟，主库挂掉的时候直接切换到备库，会存在主库的binlog日志还没重放到备库，导致数据不一致

- 主备延迟的解决方案
    - 强制读写都走主库
        - 确定业务中哪些时效性高的，哪些能延迟一段时间读取的
        - 这种强制的方式相当于放弃了扩展性，放弃了读写分离
    - 更新与插入中间sleep 一段时间
        - 这种slepp是不精确的，包括延迟超过sleep时间的还是会出现主从数据不一致的情况
    - 半同步复制
        - 事务提交的时候主库将 binlog 发给从库，从库确认收到了主库才会响应客户端事务完成

- 判断mysql服务是否出问题的方法
    - 并发连接与并发查询的区别
        - 连接数可以很高，但是查询数不会很高
        - 连接数可能是那些客户端维持长连接的连接池，保持连接，但是不一定时时刻刻都在查询
        - 查询数是数据库正在执行的语句，是影响CPU占用的重要因素
        - 线程的事务在等待锁的时候，是没有占用CPU执行时间的，因此不会算到并发查询里面
        - 只有这么设计才能保证数据库不会锁死，如果并发查询的线程用完了，都在等待锁，那数据库是无法接受请求的
    - 查表判断( select 1)
        - MHA 的中间件就是用这种方式判断的
    - 更新判断

- 误删数据怎么处理
