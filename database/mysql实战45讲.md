- count(*) 的各种性能区别
    -count(id)
        - innodb 会遍历整张表，取出每一行的id，返回给server, server统计数量
    - count(1)
        - innodb 会遍历整张表, 但不取值, server 在返回的每一行放一个 1 进去再统计数量
    - count(1) 执行得要比 count(id) 快
        - 因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作
    - count(字段)
        - 如果字段定义是 not null 的，根据行纪录统计数量
        - 如果字段定义是 null 的，根据行记录，找到字段判断，实际非空的才会统计数量

- 简单的查询语句出现速度很慢的可能
    - 可能出现锁表了
        - show processlist 命令输出 Waiting for table metadata lock 就是锁表
        - 这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了
        
        - 加读锁的时候，已经有写锁的话会读锁会阻塞
        - lock in share mode 如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住
    - 子查询结果行数过多，mysql 使用的临时表占用大量的空间
- 连接风暴
    - 连接风暴就是数据库连接数太多，无法创建更多连接，相当于应用不可用
    - 解决办法
        - 处理掉那些占着连接但是不工作的线程
            - mysql 的连接数统计是只要占用连接就算，不管当前语句状态是休眠还是运行
            - show processlist 命令找出 sleep 状态的线程
            - 这种休眠状态的连接可能是事务开始后在执行业务代码，还没提交
            - 直接kill掉对应的id的线程会导致事务没提交的话会回滚
            - 查询 information_schema 库的 innodb_trx 表 找到trx_mysql_thread_id等于刚刚show processlist的id
            - 关闭一个sql连接的命令是 kill connection id
- 数据库服务器占用内存很高的可能
    - 查看buffer pool 的设置，这个是存储引擎的缓冲池

- mysql 如何保证数据不丢失
    - 只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复
    - binlog 的写入机制
        - 事务的 binlog 是不能拆分的，不管事务多大，都要保证一次性写入
        - 事务执行过程中，先把日志写到 binlog cache
        - 事务提交的时候，再把 binlog cache 写到 binlog 文件中
        - binlog 是每个线程独有的
        - 在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能
        - 对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志
    - redo log 的写入机制
        - 事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 
        - redo log buffer 通过一定的机制持久化到磁盘，有3种策略
            - 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中
            - 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘
            - 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache
            - InnoDB 有一个后台线程，每隔1秒，就会把buffer中的日志，写到文件系统的page cache，然后调用fsync持久化到磁盘
    - binlog, redo log 是基于WAL机制的数据持久化前写日志的设计
        - 每次提交事务都要写2个日志，其实磁盘IO并不少，但是效率很高
        - redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快
        - 组提交机制，可以大幅度降低磁盘的 IOPS 消耗
    - 为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？
        - binlog 是不能被打断的。一个事务的binlog必须连续写，因此要整个事务完成后，再一起写到文件里
        - 一个线程只能有一个事务在执行
        - redo log 中间有生成的日志可以写到 redo log buffer 中,内容还能搭便车
    - 事务还没提交数据库挂掉了，会不会导致数据不一致
        - 不会，没提交的事务就不会持久化，因此不存在不一致的问题
    - mysql binlog 的日志格式和内容
        - 如果格式是 statement,就是保存原始的sql 语句

- 主备延迟产生的原因
    - 备库机器性能比主库差，导致binlog在备库重放的速度慢
    - 备库查询压力较大，主备架构的备经常备用来做查询，导致查询压力落到备库，影响了备库执行binlog速度
    - 大事务，也就是一次性修改的数据比较多，例如大表的DDL
    - mysql 主备高可用是依赖与主备延迟的，延迟时间越小，主备切换的时间越短
    - 例如备库延迟30分钟，主库挂掉的时候直接切换到备库，会存在主库的binlog日志还没重放到备库，导致数据不一致

- 主备延迟的解决方案
    - 强制读写都走主库
        - 确定业务中哪些时效性高的，哪些能延迟一段时间读取的
        - 这种强制的方式相当于放弃了扩展性，放弃了读写分离
    - 更新与插入中间sleep 一段时间
        - 这种slepp是不精确的，包括延迟超过sleep时间的还是会出现主从数据不一致的情况
    - 半同步复制
        - 事务提交的时候主库将 binlog 发给从库，从库确认收到了主库才会响应客户端事务完成

- 判断mysql服务是否出问题的方法
    - 并发连接与并发查询的区别
        - 连接数可以很高，但是查询数不会很高
        - 连接数可能是那些客户端维持长连接的连接池，保持连接，但是不一定时时刻刻都在查询
        - 查询数是数据库正在执行的语句，是影响CPU占用的重要因素
        - 线程的事务在等待锁的时候，是没有占用CPU执行时间的，因此不会算到并发查询里面
        - 只有这么设计才能保证数据库不会锁死，如果并发查询的线程用完了，都在等待锁，那数据库是无法接受请求的
    - 查表判断( select 1)
        - MHA 的中间件就是用这种方式判断的
    - 更新判断

- 误删数据怎么处理
    - 误删行
        - 可以用 Flashback 工具通过闪回把数据恢复回来
        - delete 删除的数据可以用闪回工具回复，但是 drop, truncate 命令删除的是无法用工具的
        - Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放
        - 需要确保 binlog_format=row 和 binlog_row_image=FULL
        - 不建议直接在主库上恢复，因为主库的数据可能一直变动，发现的时候已经发生很多变化了
        - 安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作
        - 然后再将确认过的临时库的数据，恢复回主库
    - 误删表
        - 这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了
        - 这个方案要求线上有定期的全量备份，并且实时备份 binlog
        - 找到最近的一个全量备份的版本，将备份恢复到一个临时库
        - 将全量备份之后的binlog日志拿到临时库中执行(除去误删除的语句)
    - 误删库
        - 对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了
        - 删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库
    - 误删数据的预防方法
        - 设置 mysql_safe_update 参数，delete, update 语句执行的时候没有条件是会报错的
        - 设置主从延迟复制
            - 有些全量备份的周期较大，binlog的日志也可能会很多，恢复时间较长
            - 可以增加一个特殊的从库，从主库那里复制的时候是有延迟的，固定延迟一个小时
            - 这样出现误操作的时候，1个小时内发现，是可以防止语句备复制到从库的
        - 上线的sql要做多个准备，执行脚本，验证脚本，备份脚本，回滚脚本

- mysql 大查询会不会把数据库内存占满
    - MySQL 采用的是边读边发的逻辑，因此对于数据量很大的查询结果来说，不会在 server 端保存完整的结果集
    - 如果客户端读结果不及时，会堵住 MySQL 的查询过程，但是不会把内存打爆

- mysql 的自增主键真的是连续的吗
    - 自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑
    - 页分裂的意思是如果上一步插入的主键是 200，下一步主键是100，就要把100的主键插入到200前面
    - 如果 200 的页存的数据满了，就得把200移出来，100弄进去，就是页分裂
