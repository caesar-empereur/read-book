## 1 章 mysql 技术体系

- 实例与数据库的区别
  * mysql 数据库是指操作系统文件的集合
  * mysql 实例是系统进程与内存区域的组成
  * 数据库实例才是处理数据的
  
- innodb 存储引擎的特点

    * 支持事务
    * 行锁设计
    * 插入缓冲
    * 二次写
    * 自适应哈希索引
    - innodb 存储引擎架构
    ![innodb](https://github.com/caesar-empereur/read-book/blob/master/photo/mysql/innodb.png)
   
    - mysql 逻辑架构
    ![innodb](https://github.com/caesar-empereur/read-book/blob/master/photo/mysql/mysql逻辑架构.png)


- mysql 的查询缓存是什么
    - mysql 查询的时候会先在查询缓存里面判断是否之前有过相同的查询
    - 是的话会查询缓存的结果直接返回
    - mysql 做更新操作的时候会清空缓存
    - 如果更新操作频繁的话，查询缓存的失效也会非常频繁，因此不建议使用

## 第 4 章 mysql 数据文件

  * **[表都是根据主键顺序组织存放的](#)**，这种存储方式的表称为 **[索引组织表](#)**
  - 索引组织表的意思是 **[mysql的行纪录都是存放在主键索引树的叶子节点上](#)**
  * 表中的数据一定会有主键，没有指定主键，系统也会创建隐式的主键
  * 页 是mysql 磁盘上最小单位的数据存储形式，也叫 块 **[每页的数据大小是16KB](#)**
  * 页存放的行记录也是有硬性定义的，最多允许存放16KB / 2-200行的记录，即7992行记录
  
## 第 5 章 mysql 索引

 - 唯一索引与普通索引的区别
    - 查询区别
        - 唯一索引查询时是根据B树查找，只要有一个满足条件的接返回
        - 普通索引查询时是根据B树查找，一直查找到到出现不满足条件的纪录就结束
        - 查找性能差别不大，因为InnoDB 的数据是按数据页为单位来读写的，查一条纪录是要将页数据加载到内存的
    - 更新区别
        - 更新的时候，如果数据页在内存，就更新内存，否则就会更新到 change buffer,这样就不用将数据从磁盘加载到内存
        - 将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge
        - 唯一索引更新的时候要校验唯一性约束，因此要在内存中判断，没用 change buffer
        - 唯一索引更新的纪录不在内存中，需要从磁盘读取到内存，这时候性能受影响
        - 普通索引更新的纪录不管在不在内存，都是更新到 change buffer
        - 普通索引减少了随机的磁盘io
    - mysql 查询语句强制使用某个索引
        - select * from table use(force) index
 * 树的数据结构
   - 普通二叉树，平衡二叉树，红黑树为什么不适合做文件索引？
   ![普通二叉树索引](https://github.com/caesar-empereur/read-book/blob/master/photo/mysql/普通二叉树索引.png)
   
   * **[如果用平衡二叉树，红黑树来构建索引的话，当数据多的时候，树的深度很大，按照每个树节点只能存一个key,行记录](#)**
   - **[这样在要经过多次磁盘的IO访问，性能相当低，因此这种树结构知识和内存和小文件](#)**


 * B 树分为 **[B-树](#)**，**[B+树](#)**，但都是 **[多路平衡查找](#)** 的树结构
   * **[B-树](#)** 的一个重要特点是 **[非叶子节点也会存储数据](#)**
      - B-树索引的特点是非叶子结点也会存储数据,也就是每个节点的多个key都是有对应的行的主键以及行记录
        ![B-树索引](https://github.com/caesar-empereur/read-book/blob/master/photo/mysql/B-树索引.png)
   * **[B+树](#)** 的一个重要特点是 **[只有叶子节点会存储数据](#)**，所有叶子节点通过链指针形成 **[排序链表](#)**
      - **[为什么B+树设计成只有叶子节点存数据？](#)**
          - 非叶子结点不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖
          - 如此一来我们查找数据进行磁盘的 IO 次数又会再次减少，数据查询的效率也会更快
      - 索引数据的插入删除需要对索引页文件的B树结构进行插入删除，分裂
      - 索引页文件的大小是16KB,按照每页(每个树结点)能存储1000个key和1000个指针
      - 只需要B树的深度为3，就可以通过索引文件维护 1000*1000*1000=10亿行记录
      - 只需要2到4次磁盘IO就能定位到某一行，而且B树根结点是常驻内存的
    ![innodb](https://github.com/caesar-empereur/read-book/blob/master/photo/mysql/B+树索引新.png)
 * 聚集索引 与 非聚集索引
  
  |索引类型 | 定义 |叶子节点存储的东西 | 定位方式 |
  |-----------|-------------------|------------|------|
  |聚集索引| 按照每张表的主键构造一棵B+树 | 行记录(数据) | 通过搜寻聚集索引B树找到行记录 |
  |非聚集索引| 按照每张表的主键外的字段构造一棵B+树| 聚集索引的键 | 通过非聚集索引B树找到 聚集索引的键，再通过聚集索引树找到行记录 |
  
  * 非聚集索引先通过找到聚集索引的键再查到到对应行记录的过程，出现了多次IO操作，这个叫 **[回表查询](#)**
  * 但不是所有非聚集索引都要经过回表查询，**[覆盖索引不需要回表](#)**
   
 * **[覆盖索引](#)**
   * 从非聚集索引中就可以得到查询的记录，而不需要查询聚集索引中的记录
       * 假设一个表的字段(id, name, sex, age), id是主键，name有索引
       * 当 select id, name from 时是覆盖索引，因为非聚集索引的叶子结点是主键(id)
       * 因此在 name 构建辅助索引的B树上直接找到了id，name 也知道了，不用再去访问聚集索引
       * 当 select id, name, sex from 时不是覆盖索引，因为 sex 信息只在聚集索引的树上，需要回表查询
   * 使用覆盖索引的一个好处是 **[辅助索引不包含整行记录的所有信息](#)**，故其大小要远小于聚集索引，因此可以减少大量的IO操作
 
 * 哈希索引
   * 哈希表的数据存储是没有任何顺序的，因此哈希索引只有在等值查询才能发挥作用，范围查询与排序是失效的，联合所以最左匹配也不行
   
 * **[mysql 索引失效的情况](#)**
   * like 以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效
   * or语句前后没有同时使用索引。当or左右查询字段只有一个是索引，该索引失效
   * 组合索引，不是使用第一列索引，索引失效
   * 不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描，优化方法： key<>0 改为 key>0 or key<0
   * B-tree索引 is null不会走,is not null会走,位图索引 is null,is not null 都会走

* 事务的特性
 
  |特性|描述|
  |-----------|-------------------|
  |原子性|一个操作，要么成功，要么失败,没有中间状态|
  |一致性|从一个状态到另一个状态的一致性|
  |隔离性|事务与事务之间的操作不能互相影响|
  |持久性|事务一旦提交就应该永久保存|

- 更新事务需要的锁与等待
```
针对同一行数据，事务A开始后未提交，事务B必须要等待A提交后才能执行

事务A：
start TRANSACTION;
update t_storage set count = count -1 where id = 1;

事务B：
start TRANSACTION;
update t_storage set count = count -1 where id = 1;

A不提交的情况下B会一直等待，超过默认时间50S会报事务等待释放锁超时
1205 - Lock wait timeout exceeded; try restarting transaction

这种等待流程上是串行的

B事务如果是查询，是不用等待A事务释放的

mysql 更新如果是针对唯一索引的某一行纪录，会用行锁锁主，再执行事务，事务提交行锁释放
行锁是锁在索引上的，如果是唯一索引，则索引会查找到第一条满足的纪录就锁住，
如果是普通索引，则索引会查找到第一个不满足的纪录就把前面的所著，也就是所著满足条件的
多行纪录
```

* 事务的分类

    |事务|描述|
    |-----------|-------------------|
    |扁平事务|事务由多个操作组成，一旦回滚必须回滚所有操作，代价很大|
    |带有保存点的扁平事务|回滚时可以只回滚最新的保存点，但是系统奔溃，所有保存点都会消失|
    |链式事务|提交事务操作和开始下一个事务操作将合并为一个原子操作|
    |嵌套事务|父事务包含子事务，子事务的提交必须在父事务提交才能生效,一个子事务回滚，其他子事务也会回滚|
    |分布式事务|事务的多个操作分布在多个服务器上|
    
## 事务的实现
- 事务的开始并不是在 begin tran, 而是在事务中的第一个查询，如果要马上启动事务，begin tran with consistent snapshot
- 事务的 **[原子性](#)** 是通过 **[undo log](#)** 来实现的
- 事务的 **[持久性](#)** 是通过 **[redo log](#)** 来实现的
    - **[原子性和一致性是为了保障数据可靠性，宕机恢复以及回滚](#)**
    - **[隔离性是为了处理多个并发读写的请求](#)**
- **[事务的隔离性是通过 (读写锁+MVCC)来实现的](#)**
- **[事务的一致性是通过原子性，持久性，隔离性来实现的](#)**

- **[日志文件的事务实现](#)**

   |'|redo|undo|
   |-----------|-------------------|-------|
   |定义|redolog称为重做日志，用来保证事务的 **[持久性](#)**|undo log用来保证事务的 **[原子性](#)**|
   |日志类型|redo通常是物理日志，记录的是页的物理修改操作(不是操作的语句)|undo是逻辑日志，根据每行记录进行记录|
   |执行过程|redo 每次事务提交时要将所有操作写入redo buffer，再刷新到磁盘，然后被删除覆盖|undo是需要回滚时执行，回滚不是将执行语句撤销，而是执行与语句相反的语句，insert回滚时会执行delete|
- binlog 与 undolog 的区别
   - **[redolog是innodb才有的，binlog是mysql server 层都有的](#)**
   - **[redolog 大小是固定的，循环写入，刷新到磁盘后会清除，无法用于回滚操作](#)**
   - redo log主要节省的是随机写磁盘的IO消耗(转成顺序写)
   - redolog 可以用于(只写到内存没写到磁盘)的奔溃后数据恢复，就是 crash safe, binlog 是没有 crash safe 能力的
   - **[只要redolog和binlog日志文件成功写入，mysql就能保证数据不丢，就是保证持久化](#)**
   - binlog 不是直接写入到磁盘的，而是写入到binlog cache, 事务提交的时候再刷新到磁盘上的
   - 每个线程是单独的binlog cache, 但是binlog文件是共享的
   - binlog 是mysql写入的日志文件，有 statement, row, mixed 等几种格式
       - statement 格式纪录的是语句的原文，体积小，但是可能导致主从数据不一致
       - row 格式纪录的是一行纪录的前后2条数据
       - row 格式不会导致主从数据不一致，但是文件体积很大，删除10万行数据就要纪录10万行纪录
       - 因此主从生产库上，执行删除的时候不要超过1000行，多的要循环删除，防止大事务
- redo log 和 binlog 是怎么关联起来的?
   - redo log 和 binlog 有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：
   - 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
   - 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务
- MySQL 怎么知道 binlog 是完整的?
   - 一个事务的 binlog 是有完整格式的：
   - statement 格式的 binlog，最后会有 COMMIT
   - row 格式的 binlog，最后会有一个 XID event
   
- **[MVCC](#)**
   - 多版本并发控制是为了应对高并发事务, MVCC 比单纯的加行锁更有效, 开销更小
   - 每行数据都存在一个版本，每次数据更新时都更新该版本，每个版本都有row trx_id, 指向每一条 undolog 日志
   - 因此每行纪录的多个版本不是实际物理存在的多个版本，而是通过 row trx_id 指向的undolog 计算出来的
   - 每行数据都有隐藏的2个列，创建版本号，删除版本号，每开启一个事务，系统版本号加一
   - 修改时Copy出当前版本随意修改，各个事务之间无干扰
   - 保存时比较版本号，如果成功提交，则覆盖原记录
   - **[MVCC](#)** 只有在 **[读提交](#)** 和 **[重复读](#)** 隔离级别下起作用
   - **[MVCC本质是对已经存在的数据做版本标记，插入数据是没法处理的](#)**
   
- **[隔离级别与脏读幻读的关系](#)**
                                 
   |读的种类|描述|解决办法|原理|办法描述
   |-----------|-------------------|--------|-----|-------------|
   |**[脏读(读未提交)](#)** |**[事务A可读到事务B未提交的数据](#)**|**[读提交](#)**|**[MVCC](#)**|事务A必须等事务B提交后才能取|
   |**[不可重复读(虚读)](#)**|**[事务A可读到事务B提交的更新数据，造成前后2次查询出的同一批数据不一样](#)**|**[重复读](#)**|**[MVCC](#)**|事务B更新操作提交后对事务A不可见|
   |**[幻读](#)**|**[事务A可读到事务B提交的插入数据，造成第二次查询出现多出来的数据，类似幻觉](#)**|**[序列化(或者重复读级别下的间隙锁+行锁=next key lock)](#)**|**[锁](#)**|最高级别，事务按照串行执行，安全性最高|
   
   - 序列化的隔离级别跟可重复读类似，只是查询语句都加了 LOCK IN SHARE MODE

- **[读提交与重复读的原理](#)**
   - **[一致性视图 (决定一个事务能读到什么数据)](#)**
       ```
       1. 未提交事务生成的记录版本，不可见。
       2. 视图生成前，已提交事务的记录版本对当前视图可见。
       3. 视图生成后，新事务产生的记录版本对当前视图不可见。
       4. 自身事务更新永远可见。
       ```
       - **[重复读](#)** 的读事务开启之后，一致性视图会在第一个查询语句的时候生成，其他事务提交后的版本 **[对当前视图不可见](#)**
       - **[读提交](#)** 的读事务开启之后，**[每次都生成新的一致性视图](#)**，其他事务提交的版本 **[对当前视图总是可见](#)**
   - **[MVCC](#)**
   ```
   mysql 每一行记录，除了真实数据之外，还会存在三个隐藏字段，用来记录额外信息。
   • DB_TRX_ID: 事务 id。
   • DB_ROLL_PTR: 回滚指针，指向 undolog。
   • ROW_ID：行 id, 与此次无关。
   
   MySQL InnoDB 里面每个事务都会有一个唯一事务 ID，它在事务开始的时候会跟 InnoDB 的事务系统申请的，
   并且严格按照顺序递增的。每次事务更新数据时，将会生成一个新的数据版本，然后会把当前的事务 id 赋值
   给当前记录的 DB_TRX_ID。并且数据更新记录（1,1000---->1,900）将会记录在 undo log（回滚日志）中，
   然后使用当前记录的 DB_ROLL_PTR 指向 und olog。
   这样 MySQL 就可以通过 DB_ROLL_PTR 找到 undolog 推导出之前版本记录内容
   ```
   ![mysql-mvcc](https://github.com/caesar-empereur/read-book/blob/master/photo/mysql/mysql-mvcc.png)
   - **[当前读于快照读](#)**
       - 快照读相当于 select 操作会去查找 undo log 中的版本链的上一个记录
       - **[当前读会读取一行记录当前的最新的已经提交的事务对应的数据](#)**
       ![mysql当前于快照读](https://github.com/caesar-empereur/read-book/blob/master/photo/mysql/mysql当前与快照读.png)

## mysql 如何保证数据不丢失
- 只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复
- binlog 的写入机制
    - 事务的 binlog 是不能拆分的，不管事务多大，都要保证一次性写入
    - binlog 是每个线程独有的
    - 在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能
    - 对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志
- redo log 的写入机制
    - 事务在执行过程中，生成的 redo log 是要先写到 redo log buffer
    - redo log buffer 通过一定的机制持久化到磁盘，有3种策略
        - 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中
        - 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘
        - 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache
        - InnoDB 有一个后台线程，每隔1秒，就会把buffer中的日志，写到文件系统的page cache，然后调用fsync持久化到磁盘
- binlog, redo log 是基于WAL机制的数据持久化前写日志的设计
    - 每次提交事务都要写2个日志，其实磁盘IO并不少，但是效率很高
    - redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快
    - 组提交机制，可以大幅度降低磁盘的 IOPS 消耗
- 事务还没提交数据库挂掉了，会不会导致数据不一致
    - 不会，没提交的事务就不会持久化，因此不存在不一致的问题
- mysql binlog 的日志格式和内容
    - 如果格式是 statement,就是保存原始的sql 语句
    - row 格式保存是的一行数据修改前后的值
    - mixed 格式是上面两种的混合
    - **[statement 格式对有些语句是有问题的,例如 set a = a+1,这个语句再执行的话数据就错乱了](#)**
    - show binlog EVENTS in 'build-binlog.000001' 可以查看日志发生的变动事件
- mysql binlog 日志恢复数据
    - mysql 开启binlog日志
    - show binlog EVENTS in 'build-binlog.000001' 查看日志发生的变动
    - 转储binlog 为 sql 文件 mysqlbinlog --no-defaults D:\dev\app\mysql\build-binlog.000001 > D:\build-binlog.sql
    - 进入mysql, source binlog.sql 恢复数据
## 误删数据怎么处理
- 误删行
    - 可以用 Flashback 工具通过闪回把数据恢复回来
    - delete 删除的数据可以用闪回工具回复，但是 drop, truncate 命令删除的是无法用工具的
    - Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放
    - 需要确保 binlog_format=row 和 binlog_row_image=FULL
    - 不建议直接在主库上恢复，因为主库的数据可能一直变动，发现的时候已经发生很多变化了
    - 安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作
    - 然后再将确认过的临时库的数据，恢复回主库
- 误删表
    - 这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了
    - 这个方案要求线上有定期的全量备份，并且实时备份 binlog
    - 找到最近的一个全量备份的版本，将备份恢复到一个临时库
    - 将全量备份之后的binlog日志拿到临时库中执行(除去误删除的语句)
- 误删库
    - 对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了
    - 删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库
- 误删数据的预防方法
    - 设置 mysql_safe_update 参数，delete, update 语句执行的时候没有条件是会报错的
    - 设置主从延迟复制
        - 有些全量备份的周期较大，binlog的日志也可能会很多，恢复时间较长
        - 可以增加一个特殊的从库，从主库那里复制的时候是有延迟的，固定延迟一个小时
        - 这样出现误操作的时候，1个小时内发现，是可以防止语句备复制到从库的
    - 上线的sql要做多个准备，执行脚本，验证脚本，备份脚本，回滚脚本

## purge

  * delete和 update 并不是直接删除数据，而是将数据打上删除标记，索引页构造的B树对应的键也是删除标记
  * puege 操作用于将 delete update 操作真正删除
  * 这么设计的原因是2为了实现mysql的mvcc，一个事务对某行提交修改时，不会真正删除，其他事务对改行也存在改动，因此需要保存改行的前一个状态，是否真正删除需要puege判断是否有另一个事务对改行操作

- 控制事务的语句
  * mysql 默认情况下，事务是自动提交的
  * START TRANSACTION | BEGIN：显式地开启一个事务
  * ROLLBACK 回滚事务
  * SET TRANSACTION 设置事务的隔离级别
  * 隐式提交事务的 语句 alter table, create index, drop table, drop index

## mysql 读写分离，主从复制
- 读写分离是指写数据写到主库，读数据读从库，需要做到主从之间的数据同步复制
- 读写分离的方案
    - 客户端直连实现
        - 少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便
        - 出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息
    - 代理方式实现
        - 对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成
        - proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂
        - proxy 的中间件会承接很多数据库连接，连接数有限制，出问题影响大
- 主从复制原理
    - 主库写入数据到 binlog, 启动 io 线程将binlog传输到从库
    - 从库接手到binlog, 启动一个线程将 binlog 内容执行到从库
    - 主从复制肯定会有延迟，并且有可能导致生产事故
- **[主从复制延迟的解决办法](#)**
    - **[打开并行复制](#)**，是指从库开启多个线程读取 binlog 的日志，加快复制的速度
    - 并行复制的策略有几种，可以按表分发，也可以按行分发，就是将不同事务的sql分给多个sql线程执行
- 主从复制适用的场景
    - 数据库访问量大，读多写少，时效性要求没那么高的场景
    - 复制延迟导致的事故大部分是因为代码里面插入后又查询更新，这种建议直接更新，或者直连主库
    - 读写分离在大部分场景是可适用的，少部分时效性要求高的可以直连主库，根据 2 8原则
    
## mysql tps qps 连接数之间的关系
- 数据库的 QPS = TPS*20, QPS = 连接数*3，这个数据是阿里云的数据库用 sysbentch 工具测试的
- 要达到5W个数据库连接，大概需要 单机16000连接数，4WQPS的 3台
![tps-qps](https://github.com/caesar-empereur/read-book/blob/master/photo/mysql/tps-qps.png)
