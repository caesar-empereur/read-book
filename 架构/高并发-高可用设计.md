- **[高并发，高可用，高性能的理解](#)**

- **[高可用的含义](#)**
![2pc](https://github.com/caesar-empereur/read-book/blob/master/photo/distri/高可用.png)


## **[高可用的设计(根据生命周期)](#)**
- **[架构设计阶段](#)**
    - **[负载均衡](#)**
        - nginx 的负载均衡可以配置心跳健康检查，根据TCP还有HTTP的
        - nginx 的负载均衡可以配置失败重试机制，单位时间内失败次数达到N将踢出服务列表
        - nginx 做反向代理时需要与后端保持连接，还要与客户端保持连接，因此连接数除以2
        - nginx 单个 worker 进程最大连接数默认是有限制的，是 1024，与操作系统是一致的ulimit -n
    - **[限流](#)**
        - 令牌桶限流，桶中固定N个令牌，固定速度往桶中添加令牌，桶满不能添加，桶空不能处理请求
        - 计数器限流，简单粗暴，限制总并发数，连接池，线程池，秒杀并发数都是计数器用法
    - **[熔断降级](#)**
        - 功能降级
            - 降级的一个重点是要明白哪些服务是可以降级的，哪些是要誓死保护的
            - 购物车，下单，结算支付，等服务是不能降级的，商品详情的商家信息，相关分类，推荐商品，热销等是可以降级的
            - 功能降级的一个关注点就是降级之后有没有保底数据，例如推荐系统不可用前端静态展示默认商品
        - 读降级：适合对读一致性要求不高的场景，从读数据库改为读缓存
        - 写降级：秒杀活动中，库存扣减在缓存处理，不直接写数据库
        - 风控降级：抢购秒杀活动中，用风控系统识别机器人等非法请求
        - 超时降级：针对非核心服务，热销榜，推荐商品等暂时不展示不影响
        - 达到失败次数降级
        - 限流降级：请求量太大时，可以引导用户到排队页面
    - **[超时重试](#)**
        - 合理的超时时间与重试次数
        - 数据库客户端超时，缓存读写超时，接口超时，中间件超时
- **[压测预案阶段](#)**
    - 压测
        - 单机调试，压测接口，压测策略，压测指标，QPS, 响应时间，成功率
        - 压测方式，线下，线上，单接口压测，链路压测
    - 预案
        - IP限流，某些IP访问量过大导致应用负载过高
        - 系统故障，CPU,内存，硬盘，TCP连接数，JVM内存等出现异常的排查和预案
        - 防止爬虫
        - 应用本身资源异常，例如tomcat线程池，连接数，数据库连接池等访问量大时是否能动态监控调整
    - 容量评估
- **[线上发布阶段](#)**
    - 增量发布于全量发布
    - 灰度发布，滚动发布
    - 借助容器编排工具实现容器的滚动发布
- **[线上故障紧急定位处理阶段](#)**
    - **[发布问题回滚阶段](#)**
        - 事务回滚
        - 代码库回滚
        - 数据库脚本回滚
    - **[线上运行监控报警阶段](#)**
        - 服务器监控，包括CPU, 内存，硬盘，网络，连接数
        - 应用监控，JVM堆内存，异常监控，接口处理监控
    - **[故障紧急响应](#)**
        - 需要指定故障排查处理的相关的手册，整理之前的各种事故经验，总结出快速的方式
        - 要有及时止损的机制，例如淘宝运营活动发布时，商品价格填写错误，需要能马上下架，关闭购买链接
- **[高可用建设是要放在应用的整个生命周期的，每个环节都有可能犯错，有些环节的错后面是没法你补得](#)**
  
## **[高并发(根据请求链路)](#)**
```
从前端开始，前后端分离部署，前端资源CDN部署
代理层，物理的负载均衡与软件的负载均衡，可以做应用的多实例部署，限流
应用层，多实例部署提高总体吞吐量，应用本身的业务逻辑可以做 缓存，异步，池化资源
应用是微服务架构的，可能存在上下游服务调用，需要做超时，重试，熔断，限流，隔离
中间层，redis，mq, mongo, 注册中心等，都可以做多实例的部署，提高负载能力与可用性
数据存储层，单数据库的sql优化，包括插入优化，查询优化，大数据量的优化设计，包括分区表

数据库单机再怎么优化也有单机的性能瓶颈，磁盘的IOPS, 连接数限制，qps, tps 限制等
因此需要考虑读写分离(针对读多写少的情况，数据实时性要求不高的)，单表数据量过大需要考虑分库分表，
什么适合做分库分表，单表数据量大到性能出现瓶颈，可能是几千万，也可能是过亿的时候，
mysql对单表的文件大小限制是到tb级别的，这个数据量基本是几十亿起步了，但是这么大的数据量的表在维护的时候
可能会出问题，加个字段，改个索引，迁移数据等问题
```

- **[缓存](#)**
    - 缓存永远比数据库，磁盘访问速度快
    - 缓存的基础上还可以用多级缓存，例如CPU的3级缓存L1,L2,L3,一次访问，没有再从内存读取
    - 多级缓存对应到系统中相当于客户端缓存，服务端应用Java缓存，redis缓存，这样一级级访问
    - 有些资源本身就是有过期属性的，例如用户的购物车，验证码
- **[池化资源](#)**
    - 数据库连接池，tomcat 线程池，tomcat 连接数，Java 线程池，Http连接池
- **[异步](#)**
    - Future, 线程池提交多个线程，Future.get() 获取最慢的线程返回
- **[扩容](#)**
    - 单体应用扩容
        - 就是部署多个实例，用 nginx 做负载均衡
        - 缺点就是应用发布，发布有问题其他功能都受影响，要死一起死
    - 功能或者服务拆分
        - 购物车服务，订单服务，库存服务，支付结算服务，商品服务，推荐服务
    - 数据库扩容
        - 分表分库
            - 分表是为了解决冷热数据的问题，分库是为了解决单数据库实例磁盘IO性能瓶颈的问题
            - 使用中间价的好处是对应用是隐藏的，侵入性最小
            - Mycat支持分库分表、读 写分离、跨库弱事务支持，跨库join/分页/排序
            - 分表可以按照时间维度分，例如按月分表，也可以按照区间维度分，1-2千万，2-3千万
            - 分库不是越多越好，库越多中间件需要保持的TCP连接数越多
            - 数据库的连接池不能只维持一个连接的原因是一个连接上存在多个事务是会导致数据不一致的
        - 读写分离
            - 读写分离是为了解决有些资源本身就是读多写少的场景，例如商品

- 一个 5 万并发的系统的设计
    - 代理层
        - nginx 在做反向代理时，需要与后端保持连接，与客户端保持连接，因此实际连接数会减半
        - 单个 worker 进程的最大连接数是 65535，反向代理连接数减半，因此需要2个 worker 进程
    - 后端
        - tomcat 的线程池默认是200，最大连接数是1W
            ```
            这么设计的原因是大部分应用不是CPU密集型的，链接建立了，线程在处理请求，
            但是大部分场景都是在等待，要么是数据库查询等待，磁盘IO等待，网络IO等待
            CPU真正执行的时间是比较短的，因此线程数会比CPU核心数大很多，提高
            CPU利用率
            
            tomcat 的连接数与线程数的关系是如果是BIO模式的话，2个是一样的，
            如果是NIO的话，连接数明显要比线程数高一个数量级
            
            NioEventLoop底层会根据系统选择select或者epoll。如果是windows系统，
            则底层使用WindowsSelectorProvider（select）实现多路复用；如果是linux，则使用epoll
            ```
        - tomcat 单实例连接数假设到1W，那么需要5个应用组成高可用的负载均衡
    - 数据库
