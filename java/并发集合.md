- ArrayBlockingQueue
```java
ArrayBlockingQueue是一个阻塞式的队列,底层以数组的形式保存数据,先进先出的顺序。支持多线程并发操作,

ArrayBlockingQueue则读写共享一个锁

final Object[] items;
int takeIndex, putIndex, count;
final ReentrantLock lock;
private final Condition notEmpty, notFull;
public void put(E e){
    lock.lockInterruptibly();
    try {
        while (count == items.length)
            notFull.await();
        enqueue(e);
    } finally {
        lock.unlock();
    }
}
//其他方法与上面类似，不加分析
```

- LinkedBlockingQueue
```java
public class LinkedBlockingQueue<E> extends AbstractQueue<E>  implements BlockingQueue<E> {
static class Node<E> {
    E item;
    Node<E> next;
}
private final int capacity;//容量
private final AtomicInteger count = new AtomicInteger();
transient Node<E> head, last;
private final ReentrantLock takeLock = new ReentrantLock();
private final ReentrantLock putLock = new ReentrantLock();
private final Condition notEmpty = takeLock.newCondition();
private final Condition notFull = putLock.newCondition();

public void put(E e) {
    int c = -1;
    Node<E> node = new Node<E>(e);
    putLock.lockInterruptibly();//可中断的锁，避免死锁
    try {
        while (count.get() == capacity) {//当队列的容量达到最大容量时即队列满了
              		notFull.await();//队列满就不增加元素，线程休眠，队列未满的条件还要等待
        }
        enqueue(node);
        c = count.getAndIncrement();
        if (c + 1 < capacity)
              notFull.signal();//当前队列中的总元素个数小于最大容量时,通知其他线程队列还未满
    } finally {
        	putLock.unlock();
    }
    if (c == 0){//当c=0时，即意味着之前的队列是空队列
             takeLock.lock();	//Condition条件对象操作之前要获取对应的锁
try {
    	notEmpty.signal();//队列为空时, 通知其他还在等待队列为空条件的线程,队列已经为空
} finally {
    	takeLock.unlock();
}
    }
}

}
LinkedBlockingQueue是一个单向链表实现的阻塞队列，先进先出的顺序。支持多线程并发操作。
相比于数组实现的ArrayBlockingQueue的有界，LinkedBlockingQueue可认为是无界队列。多用于任务队列
final int capacity; 阻塞队列所能存储的最大容量,入队和出队使用的不是同一个锁,操作不会互斥,
LinkedBlockingQueue比ArrayBlockingQueue有更高的吞吐量，但是性能表现更难预测
```

- CopyOnWriteArrayList
```java
class CopyOnWriteArrayList<E>  implements List<E>, RandomAccess {

final transient ReentrantLock lock = new ReentrantLock();
private transient volatile Object[] array;

public boolean add(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        int len = array.length;
        Object[] newElements = Arrays.copyOf(array, len + 1);
        newElements[len] = e;
  array=newElements;
        return true;
    } finally {
        lock.unlock();
    }
}
//get操作完全是没有加锁或者同步操作的如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，
因为写的时候不会锁住旧的CopyOnWriteArrayList
public E get(int index) {
            return (E) this.array[index]
      }
}

CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，
复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器
进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。
```

- CopyOnWriteArraySet
```java
public class CopyOnWriteArraySet<E> extends AbstractSet<E> {

private final CopyOnWriteArrayList<E> al;

public boolean add(E e) {
    return al.addIfAbsent(e);
}
}
```

- ThreadPoolExecutor
```
public class ThreadPoolExecutor extends AbstractExecutorService {
private final AtomicInteger atomicInteger = new AtomicInteger(-567870912);
private final BlockingQueue<Runnable> workQueue;
private final ReentrantLock mainLock = new ReentrantLock();
private final HashSet<Worker> workers = new HashSet<Worker>();
private final Condition termination = mainLock.newCondition();
private volatile ThreadFactory threadFactory;
private volatile RejectedExecutionHandler handler = new AbortPolicy();
private volatile boolean allowCoreThreadTimeOut;
private volatile int corePoolSize, int maximumPoolSize, long keepAliveTime;

public void execute(Runnable command) {
int c = atomicInteger.get();	//c=-567870912
if (workerCountOf(c) < corePoolSize) { // 1当前池中线程数量少于核心线程数，新建线程执行任务
    if (addWorker(command, true))
        return;
    c = atomicInteger.get();
}
if (isRunning(c) && workQueue.offer(command)) { // 2.核心池已满，但任务队列未满，添加到队列中
    int recheck = atomicInteger.get();
    if (! isRunning(recheck) && remove(command))
        reject(command);
    if (workerCountOf(recheck) == 0)
        addWorker(null, false);
    return;
}
if (!addWorker(command, false)) //3.核心池已满，队列已满，试着创建一个新线程
    //如果创建新线程失败了，说明线程池被关闭或者线程池完全满了，拒绝任务
    reject(command);
}

private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = atomicInteger.get();
        int rs = runStateOf(c);
  //线程池是停止状态并且队列不为空，加入的线程任务为空，则返回执行不成功
        if (rs >= SHUTDOWN && ! (rs == SHUTDOWN && firstTask == null && ! workQueue.isEmpty()))
            return false;
        for (;;) { //自旋锁的应用
            int wc = workerCountOf(c); //获取池中工作线程数，大于默认容量或者核心线程数，则不能添加到 worker 线程
            if (wc >= CAPACITY || wc >= corePoolSize)
                return false;
            if (atomicInteger.getAndIncrement())
                break retry;
            c = atomicInteger.get(); 
            if (runStateOf(c) != rs)
                continue retry; //如果线程池状态发生改变，回到最外层循环重新开始
        }
    }
    boolean workerStarted = false, workerAdded = false;
    Worker w = null;
    try {
        w = new Worker(firstTask);
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                int rs = runStateOf(atomicInteger.get());
                    //线程池是运行状态，才能把 worker 线程添加到 worker 集合中
                if (rs < SHUTDOWN || (rs == SHUTDOWN && firstTask == null)) {
                    workers.add(w);
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s; //更新最大线程数为 worker 集合size
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                t.start();   workerStarted = true; //启动线程，这里是调用 runWorker()方法
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w);
    }
    return workerStarted;
}

private void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // allow interrupts
    boolean completedAbruptly = true;
    try {
         //如果传进来的worker线程是空的，则从队列中拿出线程执行
        while (task != null || (task = getTask()) != null) {
            //规定时间内没有拿到线程，说明队列为空，当前线程池中不需要
            //那么多的线程存活可以把多余核心线程数的线程停止
            w.lock();
            if (//线程池不是运行状态的，中断线程)
                wt.interrupt();
            try {  task.run(); } //这里就是真正的执行线程
      finally { task = null; w.completedTasks++;  w.unlock(); }
        }
        completedAbruptly = false;
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}
}
```

- ThreadPoolExecutor 参数解释
```

corePoolSize：         核心线程数，会一直存活，即使没有任务，线程池也会维护线程的最少数量
maximumPoolSize： 线程池维护线程的最大数量
keepAliveTime：      线程池维护线程所允许的空闲时间，当线程空闲时间达到keepAliveTime，该线程会退出，直到线程数量等于corePoolSize。
如果allowCoreThreadTimeout设置为true，则所有线程均会退出直到线程数量为0。
unit： 线程池维护线程所允许的空闲时间的单位、可选参数值为：TimeUnit中的几个静态属性：
workQueue： 线程池所使用的缓冲队列，常用的是：java.util.concurrent.ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue
handler： 线程池中的数量大于maximumPoolSize，对拒绝任务的处理策略，默认值ThreadPoolExecutor.AbortPolicy()。

public class Executors {
    public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
    }
    public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS,  new LinkedBlockingQueue<Runnable>());
    }
    public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
       return new ThreadPoolExecutor(corePoolSize, Integer.MAX_VALUE, 0L, NANOSECONDS,  new DelayedWorkQueue<Runnable>());
    }
    public static ExecutorService newSingleThreadExecutor() {
        return new ThreadPoolExecutor(1, 1,  0L, TimeUnit.MILLISECONDS,  new LinkedBlockingQueue<Runnable>());
    }
}
public interface ScheduledExecutorService extends ExecutorService {
    ScheduledFuture<?> schedule(Runnable command, long delay, TimeUnit unit);
    <V> ScheduledFuture<V> schedule(Callable<V> callable,  long delay, TimeUnit unit);
    ScheduledFuture<?> scheduleAtFixedRate(Runnable command,  long initialDelay,  long period,  TimeUnit unit);
    ScheduledFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);
}
```

- ConcurrentHashMap-jdk1.7
![ConcurrentHashMap](https://github.com/caesar-empereur/read-book/blob/master/photo/ConcurrentHashMap-1.8.png)

- ConcurrentHashMap-jdk1.8
```
    public V put(K key, V value) {
        return putVal(key, value, false);
    }

    final V putVal(K key, V value, boolean onlyIfAbsent) {
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            /*
            哈希值 跟 数组长度减1 做一个与操作, 相当于直接取哈希值的低位(数组长度)部分
            数组长度16减1 就是 15，所有 15以下的值与之进行与操作都是得到自身
            */
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                //如果算出的这个下标的节点是空的，CAS存入该节点
                if (casTabAt(tab, i, null,new Node<K,V>(hash, key, value, null)))
                    break;
            }
            else if ((fh = f.hash) == MOVED)
                //判断到当前下标的节点被标记为扩容操作，则帮忙扩容，启用多个线程扩容
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                synchronized (f) {  // 枷锁的粒度只到 Node, 比原来的分段锁粒度更小了
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) { // 说明是链表节点
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                // 如果该小标的 Node key, value 跟当前put 的一样，把旧的value替换掉
                                if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                //在循环里面一直找到寻找，直到找到链表的尾部，把 构造的 Node 节点放到尾部
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key, value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                // 上面的链表遍历过程，如果遍历次数(链表长度)大于一个值，把链表标成树结构
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }
    
    public V get(Object key) {
        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
        int h = spread(key.hashCode());
        if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) {
            if ((eh = e.hash) == h) { // 如果定位到的小标的哈希值跟当前的 key 哈希值一样的话
                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                    // Node 的 key 跟 当前 key 是一样的话，直接返回 value
                    return e.val;
            }
            else if (eh < 0)
                return (p = e.find(h, key)) != null ? p.val : null;
            while ((e = e.next) != null) { // 如果下标对应的 Node 是个链表，遍历链表
                if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek))))
                    return e.val;
            }
        }
        return null;
    }
```
- ConcurrentHashMap

    - ConcurrentHashMap put() 方法代码流程
        - 如果没有初始化就先调用initTable（）方法来进行初始化过程
            - 初始化如果遇到其他线程在扩容，当前线程需要 yield 挂起
        - 如果没有hash冲突就直接CAS插入
        - 判断数组下表的第一个元素是否被标记为正在扩容，是的话当前线程加入到扩容操作里面
        - 如果存在hash冲突，就加锁来保证线程安全，这里有两种情况，一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入，
        - 最后一个如果Hash冲突时会形成Node链表，在链表长度超过8，Node数组超过64时会将链表结构转换为红黑树的结构，break再一次进入循环
        - 如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容
    
    - ConcurrentHashMap 总结
    - 1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（Node）
    - 1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了
    - 1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档
    - 1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点
    - 因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了
    - JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然
