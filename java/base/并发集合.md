- **[ArrayBlockingQueue]()**
```
ArrayBlockingQueue是一个阻塞式的队列,底层以数组的形式保存数据,先进先出的顺序。支持多线程并发操作,

ArrayBlockingQueue则读写共享一个锁

public class ArrayBlockingQueue<E> extends AbstractQueue<E> implements BlockingQueue<E>

final Object[] items;
int takeIndex, putIndex, count;
final ReentrantLock lock;
private final Condition notEmpty, notFull;

public void put(E e){
    lock.lockInterruptibly();
    try {
        while (count == items.length)
            notFull.await();
        enqueue(e);
    } finally {
        lock.unlock();
    }
}

public boolean offer(E e) {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        if (count == items.length)
            return false;
        else {
            enqueue(e);
            return true;
        }
    } finally {
        lock.unlock();
    }
}

public E peek() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        return itemAt(takeIndex); // null when queue is empty
    } finally {
        lock.unlock();
    }
}

public E poll() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        return (count == 0) ? null : dequeue();
    } finally {
        lock.unlock();
    }
}

public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == 0)
            notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
}
//其他方法与上面类似，不加分析
```

- **[LinkedBlockingQueue]()**
```java
public class LinkedBlockingQueue<E> extends AbstractQueue<E>  implements BlockingQueue<E> {
static class Node<E> {
    E item;
    Node<E> next;
}
private final int capacity;//容量
private final AtomicInteger count = new AtomicInteger();
transient Node<E> head, last;
private final ReentrantLock takeLock = new ReentrantLock();
private final ReentrantLock putLock = new ReentrantLock();
private final Condition notEmpty = takeLock.newCondition();
private final Condition notFull = putLock.newCondition();

public void put(E e) {
    int c = -1;
    Node<E> node = new Node<E>(e);
    putLock.lockInterruptibly();//可中断的锁，避免死锁
    try {
        while (count.get() == capacity) {//当队列的容量达到最大容量时即队列满了
            notFull.await();//队列满就不增加元素，线程休眠，队列未满的条件还要等待
        }
        enqueue(node);
        c = count.getAndIncrement();
        if (c + 1 < capacity)
          notFull.signal();//当前队列中的总元素个数小于最大容量时,通知其他线程队列还未满
    } finally {
        putLock.unlock();
    }
    if (c == 0){//当c=0时，即意味着之前的队列是空队列
        takeLock.lock();	//Condition条件对象操作之前要获取对应的锁
    try {
        notEmpty.signal();//队列为空时, 通知其他还在等待队列为空条件的线程,队列已经为空
    } finally {
        takeLock.unlock();
    }

}
LinkedBlockingQueue是一个单向链表实现的阻塞队列，先进先出的顺序。支持多线程并发操作。
相比于数组实现的ArrayBlockingQueue的有界，LinkedBlockingQueue可认为是无界队列。多用于任务队列
final int capacity; 阻塞队列所能存储的最大容量,入队和出队使用的不是同一个锁,操作不会互斥,
LinkedBlockingQueue比ArrayBlockingQueue有更高的吞吐量，但是性能表现更难预测
```

- **[CopyOnWriteArrayList]()**
```java
class CopyOnWriteArrayList<E>  implements List<E>, RandomAccess {

final transient ReentrantLock lock = new ReentrantLock();
private transient volatile Object[] array;

public boolean add(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        int len = array.length;
        Object[] newElements = Arrays.copyOf(array, len + 1);
        newElements[len] = e;
        array=newElements;
        return true;
    } finally {
        lock.unlock();
    }
}
/*
get操作完全是没有加锁或者同步操作的如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，
读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList
 */
    public E get(int index) {
        return (E) this.array[index];
    }
}

CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，
复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器
进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。
```

- **[CopyOnWriteArraySet]()**
```java
public class CopyOnWriteArraySet<E> extends AbstractSet<E> {

private final CopyOnWriteArrayList<E> al;

    public boolean add(E e) {
        return al.addIfAbsent(e);
    }
}
```

- **[ConcurrentHashMap-jdk1.7]()**
![ConcurrentHashMap](https://github.com/caesar-empereur/read-book/blob/master/photo/ConcurrentHashMap-1.8.png)

- **[ConcurrentHashMap-jdk1.8]()**
```
    public V put(K key, V value) {
        return putVal(key, value, false);
    }

    final V putVal(K key, V value, boolean onlyIfAbsent) {
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            /*
            哈希值 跟 数组长度减1 做一个与操作, 相当于直接取哈希值的低位(数组长度)部分
            数组长度16减1 就是 15，所有 15以下的值与之进行与操作都是得到自身
            */
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                //如果算出的这个下标的节点是空的，CAS存入该节点
                if (casTabAt(tab, i, null,new Node<K,V>(hash, key, value, null)))
                    break;
            }
            else if ((fh = f.hash) == MOVED)
                //判断到当前下标的节点被标记为扩容操作，则帮忙扩容，启用多个线程扩容
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                synchronized (f) {  // 枷锁的粒度只到 Node, 比原来的分段锁粒度更小了
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) { // 说明是链表节点
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                // 如果该小标的 Node key, value 跟当前put 的一样，把旧的value替换掉
                                if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                //在循环里面一直找到寻找，直到找到链表的尾部，把 构造的 Node 节点放到尾部
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key, value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                // 上面的链表遍历过程，如果遍历次数(链表长度)大于一个值，把链表标成树结构
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }
    
    public V get(Object key) {
        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
        int h = spread(key.hashCode());
        if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) {
            if ((eh = e.hash) == h) { // 如果定位到的小标的哈希值跟当前的 key 哈希值一样的话
                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                    // Node 的 key 跟 当前 key 是一样的话，直接返回 value
                    return e.val;
            }
            else if (eh < 0)
                return (p = e.find(h, key)) != null ? p.val : null;
            while ((e = e.next) != null) { // 如果下标对应的 Node 是个链表，遍历链表
                if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek))))
                    return e.val;
            }
        }
        return null;
    }
```
- ConcurrentHashMap
    - **[ConcurrentHashMap put() 方法代码流程]()**
        - 如果没有初始化就先调用initTable（）方法来进行初始化过程
            - 初始化如果遇到其他线程在扩容，当前线程需要 yield 挂起
        - 如果没有hash冲突就直接CAS插入
        - 判断数组下表的第一个元素是否被标记为正在扩容，是的话当前线程加入到扩容操作里面
        - 如果存在hash冲突，就加锁来保证线程安全，这里有两种情况，一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入，
        - 最后一个如果Hash冲突时会形成Node链表，在链表长度超过8，Node数组超过64时会将链表结构转换为红黑树的结构，break再一次进入循环
        - 如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容
    
    - **[ConcurrentHashMap 总结]()**
        - 1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（Node）
        - 1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了
        - 1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档
        - 1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点
        - 因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了
        - JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然
